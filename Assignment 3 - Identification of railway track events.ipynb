{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f92d332",
   "metadata": {},
   "source": [
    "# Assignment 3 - Identification of railway track events\n",
    "### Industrial AI and eMainteance – Part I, D7015B\n",
    "\n",
    "<p style=\"text-align: right;\"><em>by Martin Olin</em></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bd6683",
   "metadata": {},
   "source": [
    "### Problem description\n",
    "\n",
    "One way to detect issues with the railway track is to measure the interactions between the wheels and the railway track with acceleration sensors that pick up vibrations and by analyzing the measured frequencies and wave patterns one can deduce defects. In this assignment such measurements are provided and analyzied for classification by a linear SVM. \n",
    "\n",
    "### Overview\n",
    "To accomplish this, the data is first loaded from three different sources and combined into a single dataset. Irrelevant data is discarded, and the remaining data is binary classified as either \"good\" or \"defect.\" Next, the dataset is split into training and test sets using an 80/20 ratio, and 5-fold cross-validation is performed to evaluate model stability. Finally, two filter methods and two wrapper methods are demonstrated to show how they can be used to preprocess the data and reduce dimensionality.\n",
    "\n",
    "### Method\n",
    "\n",
    "First a few libraries were loaded as shown by the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4cec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "np.set_printoptions(legacy='1.25') #nicer print\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc38265",
   "metadata": {},
   "source": [
    "Next the data sources were loaded, and as demonstrated these does contain different number of features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ebe388e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 19)\n",
      "(49, 19)\n",
      "(49, 22)\n"
     ]
    }
   ],
   "source": [
    "df_trail1 = pd.read_csv('Trail1_extracted_features_acceleration_m1ai1-1.csv')\n",
    "df_trail2 = pd.read_csv('Trail2_extracted_features_acceleration_m1ai1.csv')\n",
    "df_trail3 = pd.read_csv('Trail3_extracted_features_acceleration_m2ai0.csv')\n",
    "\n",
    "dfs=[df_trail1, df_trail2, df_trail3]\n",
    "\n",
    "print(df_trail1.shape)\n",
    "print(df_trail2.shape)\n",
    "print(df_trail3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d833ca",
   "metadata": {},
   "source": [
    "The names of these were as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21526961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mean', 'std', 'max', 'min', 'range', 'skewness', 'kurtosis', 'rms',\n",
      "       'crest_factor', 'variance', 'zero_crossings', 'dominant_freq',\n",
      "       'spectral_energy', 'spectral_centroid', 'spectral_bandwidth',\n",
      "       'spectral_flatness', 'start_time', 'event', 'axle'],\n",
      "      dtype='object')\n",
      "Index(['mean', 'std', 'max', 'min', 'range', 'skewness', 'kurtosis', 'rms',\n",
      "       'crest_factor', 'variance', 'zero_crossings', 'dominant_freq',\n",
      "       'spectral_energy', 'spectral_centroid', 'spectral_bandwidth',\n",
      "       'spectral_flatness', 'start_time', 'event', 'axle'],\n",
      "      dtype='object')\n",
      "Index(['mean', 'std', 'max', 'min', 'range', 'skewness', 'kurtosis', 'rms',\n",
      "       'crest_factor', 'variance', 'zero_crossings', 'dominant_freq',\n",
      "       'spectral_energy', 'spectral_centroid', 'spectral_bandwidth',\n",
      "       'spectral_flatness', 'start_time', 'event', 'axle', 'cluster', 'tsne_1',\n",
      "       'tsne_2'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for data in dfs:\n",
    "    print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0e339a",
   "metadata": {},
   "source": [
    "The data was not normalized to start with, here showing 4 data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a445ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>range</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>rms</th>\n",
       "      <th>crest_factor</th>\n",
       "      <th>variance</th>\n",
       "      <th>...</th>\n",
       "      <th>spectral_energy</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>spectral_flatness</th>\n",
       "      <th>start_time</th>\n",
       "      <th>event</th>\n",
       "      <th>axle</th>\n",
       "      <th>cluster</th>\n",
       "      <th>tsne_1</th>\n",
       "      <th>tsne_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.000039</td>\n",
       "      <td>0.013216</td>\n",
       "      <td>0.040186</td>\n",
       "      <td>-0.057198</td>\n",
       "      <td>0.097384</td>\n",
       "      <td>-0.227469</td>\n",
       "      <td>0.167842</td>\n",
       "      <td>0.013216</td>\n",
       "      <td>3.040798</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>302.214869</td>\n",
       "      <td>384.529489</td>\n",
       "      <td>0.004821</td>\n",
       "      <td>9.901992</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.349625</td>\n",
       "      <td>5.166960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.078127</td>\n",
       "      <td>0.582892</td>\n",
       "      <td>-0.804829</td>\n",
       "      <td>1.387721</td>\n",
       "      <td>-0.781602</td>\n",
       "      <td>21.367413</td>\n",
       "      <td>0.078127</td>\n",
       "      <td>7.460853</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>313.137674</td>\n",
       "      <td>196.101692</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>8.238000</td>\n",
       "      <td>joint X</td>\n",
       "      <td>A2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.899679</td>\n",
       "      <td>5.718000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.000046</td>\n",
       "      <td>0.031775</td>\n",
       "      <td>0.282569</td>\n",
       "      <td>-0.258469</td>\n",
       "      <td>0.541038</td>\n",
       "      <td>0.056260</td>\n",
       "      <td>13.399656</td>\n",
       "      <td>0.031775</td>\n",
       "      <td>8.892871</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>268.376952</td>\n",
       "      <td>205.494690</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>31.475000</td>\n",
       "      <td>crossing</td>\n",
       "      <td>A1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.467289</td>\n",
       "      <td>5.115012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.017330</td>\n",
       "      <td>0.098209</td>\n",
       "      <td>-0.102123</td>\n",
       "      <td>0.200331</td>\n",
       "      <td>-0.039548</td>\n",
       "      <td>3.875768</td>\n",
       "      <td>0.017330</td>\n",
       "      <td>5.667109</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>268.200128</td>\n",
       "      <td>308.119171</td>\n",
       "      <td>0.002903</td>\n",
       "      <td>30.929000</td>\n",
       "      <td>squat H</td>\n",
       "      <td>A1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.626651</td>\n",
       "      <td>4.825243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean       std       max       min     range  skewness   kurtosis  \\\n",
       "8  -0.000039  0.013216  0.040186 -0.057198  0.097384 -0.227469   0.167842   \n",
       "5   0.000015  0.078127  0.582892 -0.804829  1.387721 -0.781602  21.367413   \n",
       "30 -0.000046  0.031775  0.282569 -0.258469  0.541038  0.056260  13.399656   \n",
       "29 -0.000008  0.017330  0.098209 -0.102123  0.200331 -0.039548   3.875768   \n",
       "\n",
       "         rms  crest_factor  variance  ...  spectral_energy  spectral_centroid  \\\n",
       "8   0.013216      3.040798  0.000175  ...         0.000007         302.214869   \n",
       "5   0.078127      7.460853  0.006104  ...         0.000246         313.137674   \n",
       "30  0.031775      8.892871  0.001010  ...         0.000040         268.376952   \n",
       "29  0.017330      5.667109  0.000300  ...         0.000012         268.200128   \n",
       "\n",
       "    spectral_bandwidth  spectral_flatness  start_time     event    axle  \\\n",
       "8           384.529489           0.004821    9.901992    normal  normal   \n",
       "5           196.101692           0.000318    8.238000   joint X      A2   \n",
       "30          205.494690           0.000959   31.475000  crossing      A1   \n",
       "29          308.119171           0.002903   30.929000   squat H      A1   \n",
       "\n",
       "   cluster    tsne_1    tsne_2  \n",
       "8        0 -2.349625  5.166960  \n",
       "5        1  1.899679  5.718000  \n",
       "30       0 -0.467289  5.115012  \n",
       "29       0 -1.626651  4.825243  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trail3.sample(n=4, random_state=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2acad3",
   "metadata": {},
   "source": [
    "The third data set had 3 extra columns in the end; cluster, tsne_1 and tsne_2. In order to combine all dataset these data columns were dropped by the code below and the data sets were combined into one common dataset (df_combined): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ca767a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>range</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>rms</th>\n",
       "      <th>crest_factor</th>\n",
       "      <th>variance</th>\n",
       "      <th>zero_crossings</th>\n",
       "      <th>dominant_freq</th>\n",
       "      <th>spectral_energy</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>spectral_flatness</th>\n",
       "      <th>start_time</th>\n",
       "      <th>event</th>\n",
       "      <th>axle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.000018</td>\n",
       "      <td>0.078133</td>\n",
       "      <td>0.582892</td>\n",
       "      <td>-0.804829</td>\n",
       "      <td>1.387721</td>\n",
       "      <td>-0.780089</td>\n",
       "      <td>21.357968</td>\n",
       "      <td>0.078133</td>\n",
       "      <td>7.460227</td>\n",
       "      <td>0.006105</td>\n",
       "      <td>931</td>\n",
       "      <td>325.0</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>312.947675</td>\n",
       "      <td>193.284416</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>8.498000</td>\n",
       "      <td>squat B</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.013004</td>\n",
       "      <td>0.042284</td>\n",
       "      <td>-0.050154</td>\n",
       "      <td>0.092438</td>\n",
       "      <td>-0.016909</td>\n",
       "      <td>0.600969</td>\n",
       "      <td>0.013005</td>\n",
       "      <td>3.251452</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>97</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>392.130148</td>\n",
       "      <td>433.008841</td>\n",
       "      <td>0.004329</td>\n",
       "      <td>13.442969</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean       std       max       min     range  skewness   kurtosis  \\\n",
       "6  -0.000018  0.078133  0.582892 -0.804829  1.387721 -0.780089  21.357968   \n",
       "13  0.000065  0.013004  0.042284 -0.050154  0.092438 -0.016909   0.600969   \n",
       "\n",
       "         rms  crest_factor  variance  zero_crossings  dominant_freq  \\\n",
       "6   0.078133      7.460227  0.006105             931          325.0   \n",
       "13  0.013005      3.251452  0.000169              97          300.0   \n",
       "\n",
       "    spectral_energy  spectral_centroid  spectral_bandwidth  spectral_flatness  \\\n",
       "6          0.000246         312.947675          193.284416           0.000317   \n",
       "13         0.000007         392.130148          433.008841           0.004329   \n",
       "\n",
       "    start_time    event    axle  \n",
       "6     8.498000  squat B      A1  \n",
       "13   13.442969   normal  normal  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[2]=dfs[2].drop(['cluster'\t,'tsne_1','tsne_2'],axis=1)\n",
    "df_combined= pd.concat(dfs,axis=0)\n",
    "print(df_combined.shape)\n",
    "df_combined.sample(n=2, random_state=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a9d3b9",
   "metadata": {},
   "source": [
    "The Assignment also specicied that we should drop axles and start_time. We weere also to change the events into 0 for normal and 1 otherwise: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c20a112e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>range</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>rms</th>\n",
       "      <th>crest_factor</th>\n",
       "      <th>variance</th>\n",
       "      <th>zero_crossings</th>\n",
       "      <th>dominant_freq</th>\n",
       "      <th>spectral_energy</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>spectral_flatness</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.000018</td>\n",
       "      <td>0.078133</td>\n",
       "      <td>0.582892</td>\n",
       "      <td>-0.804829</td>\n",
       "      <td>1.387721</td>\n",
       "      <td>-0.780089</td>\n",
       "      <td>21.357968</td>\n",
       "      <td>0.078133</td>\n",
       "      <td>7.460227</td>\n",
       "      <td>0.006105</td>\n",
       "      <td>931</td>\n",
       "      <td>325.0</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>312.947675</td>\n",
       "      <td>193.284416</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.013004</td>\n",
       "      <td>0.042284</td>\n",
       "      <td>-0.050154</td>\n",
       "      <td>0.092438</td>\n",
       "      <td>-0.016909</td>\n",
       "      <td>0.600969</td>\n",
       "      <td>0.013005</td>\n",
       "      <td>3.251452</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>97</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>392.130148</td>\n",
       "      <td>433.008841</td>\n",
       "      <td>0.004329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean       std       max       min     range  skewness   kurtosis  \\\n",
       "6  -0.000018  0.078133  0.582892 -0.804829  1.387721 -0.780089  21.357968   \n",
       "13  0.000065  0.013004  0.042284 -0.050154  0.092438 -0.016909   0.600969   \n",
       "\n",
       "         rms  crest_factor  variance  zero_crossings  dominant_freq  \\\n",
       "6   0.078133      7.460227  0.006105             931          325.0   \n",
       "13  0.013005      3.251452  0.000169              97          300.0   \n",
       "\n",
       "    spectral_energy  spectral_centroid  spectral_bandwidth  spectral_flatness  \\\n",
       "6          0.000246         312.947675          193.284416           0.000317   \n",
       "13         0.000007         392.130148          433.008841           0.004329   \n",
       "\n",
       "    event  \n",
       "6       1  \n",
       "13      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined=df_combined.drop(['start_time','axle'],axis=1)\n",
    "df_combined['event']= df_combined['event'].apply(lambda x: 0 if 'normal' in str(x) else 1)\n",
    "df_combined.sample(n=2, random_state=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc0bd45",
   "metadata": {},
   "source": [
    "Next to normalize all data the following code was used:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e932df",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2770005",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaleing=MinMaxScaler()\n",
    "df_preprocessed_grade_3=pd.DataFrame(scaleing.fit_transform(df_combined), columns=df_combined.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79333f7",
   "metadata": {},
   "source": [
    "In order to split the data into a test and training part 80/20, train_test_split was used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c6e40ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df_preprocessed_grade_3['event']\n",
    "x=df_preprocessed_grade_3.drop(['event'],axis=1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x,y,test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced34583",
   "metadata": {},
   "source": [
    "#### Grade 4\n",
    "\n",
    "Cross-valdiation was performed by the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cc68cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d0f2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold nr 0 got acc:1.0\n",
      "fold nr 1 got acc:0.9583333333333334\n",
      "fold nr 2 got acc:0.875\n",
      "fold nr 3 got acc:1.0\n",
      "fold nr 4 got acc:0.9166666666666666\n",
      "model accuracy on average = 0.95\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def CrossVal(X_train,Y_train,k=5):\n",
    "    kfoldsize=round(len(X_train)/k) #need to be deviceable with k, this is the case here 120/5 so no checks are implemented.\n",
    "    accuracies= []\n",
    "    for i in range(k):\n",
    "        X_test_cross=[]\n",
    "        X_train_cross=[]\n",
    "        Y_test_cross=[]\n",
    "        Y_train_cross=[]\n",
    "        for fold in range(k):\n",
    "            if fold==i:\n",
    "                X_test_cross=X_train[kfoldsize*i:kfoldsize*(i+1)]\n",
    "                Y_test_cross=Y_train[kfoldsize*i:kfoldsize*(i+1)]\n",
    "            else:\n",
    "                X_train_cross.append(X_train[kfoldsize*fold:kfoldsize*(fold+1)])\n",
    "                Y_train_cross.append(Y_train[kfoldsize*fold:kfoldsize*(fold+1)])\n",
    "        X_train_cross= pd.concat(X_train_cross,axis=0)\n",
    "        Y_train_cross= pd.concat(Y_train_cross,axis=0)\n",
    "\n",
    "        model=SVC()\n",
    "        model.fit(X_train_cross,Y_train_cross)\n",
    "        y_pred= model.predict(X_test_cross)\n",
    "        accuracies.append(accuracy_score(Y_test_cross,y_pred))\n",
    "    return accuracies\n",
    "accuracies=CrossVal(X_train,Y_train,5)\n",
    "\n",
    "for acc in range(len(accuracies)):\n",
    "    print(\"fold nr \" + str(acc) + \" got acc:\" + str(accuracies[acc]))\n",
    "print(\"model accuracy on average = \" + str(np.mean(accuracies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72beb7d9",
   "metadata": {},
   "source": [
    "The average cross-validation result could be compared to what happens when all the training data is used for training the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8de3163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy from using all the training data was: 1.0\n"
     ]
    }
   ],
   "source": [
    "model=SVC()\n",
    "model.fit(X_train,Y_train)\n",
    "y_pred= model.predict(X_test)\n",
    "acc=accuracy_score(Y_test,y_pred)\n",
    "print(\"the accuracy from using all the training data was: \" + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1176eef6",
   "metadata": {},
   "source": [
    "Getting a perfect result like 100% can be problematic, still the cross-validation also yeilded high results so it is a good idea to train with all the available training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ae21e5",
   "metadata": {},
   "source": [
    "#### Grade 5 \n",
    "Four feature selection algorithms were implemented, these are important when working with very large datasets but not really needed in this case.\n",
    "\n",
    "The Code below demonstrates a filter method, Pearson Correlation, a low correlation means that we can remove the feautre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96c2f5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dominant_freq         0.013005\n",
      "mean                  0.058047\n",
      "zero_crossings        0.121471\n",
      "skewness              0.157527\n",
      "spectral_bandwidth    0.351987\n",
      "spectral_centroid     0.377106\n",
      "spectral_flatness     0.379142\n",
      "spectral_energy       0.402178\n",
      "variance              0.405861\n",
      "rms                   0.490274\n",
      "std                   0.490287\n",
      "max                   0.508304\n",
      "range                 0.525619\n",
      "min                   0.531723\n",
      "kurtosis              0.624201\n",
      "crest_factor          0.769177\n",
      "event                 1.000000\n",
      "Name: event, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "corr_matrix=df_combined.corr(method='pearson')\n",
    "corr_columns=abs(corr_matrix['event']).sort_values(ascending=True)\n",
    "features= corr_columns.index.tolist()\n",
    "print(corr_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbec9b1",
   "metadata": {},
   "source": [
    "For a linear kernel we can then remove the feature with the least correlation, here showing the average accuracy from five folded cross validation and the top correlated features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41c66418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 top features correlations above absolut values of 0.01300475519112022 give an mean accuracy = 0.9583333333333334 k-fold accuracies = [1.0, 0.9583333333333334, 0.875, 1.0, 0.9583333333333334]\n",
      "14 top features correlations above absolut values of 0.05804740976371208 give an mean accuracy = 0.9583333333333334 k-fold accuracies = [1.0, 0.9583333333333334, 0.875, 1.0, 0.9583333333333334]\n",
      "13 top features correlations above absolut values of 0.12147061847455003 give an mean accuracy = 0.95 k-fold accuracies = [1.0, 0.9583333333333334, 0.875, 0.9583333333333334, 0.9583333333333334]\n",
      "12 top features correlations above absolut values of 0.157526602392071 give an mean accuracy = 0.95 k-fold accuracies = [1.0, 0.9583333333333334, 0.875, 0.9583333333333334, 0.9583333333333334]\n",
      "11 top features correlations above absolut values of 0.35198744069748444 give an mean accuracy = 0.95 k-fold accuracies = [1.0, 0.9583333333333334, 0.875, 0.9583333333333334, 0.9583333333333334]\n",
      "10 top features correlations above absolut values of 0.37710571072667226 give an mean accuracy = 0.95 k-fold accuracies = [1.0, 0.9583333333333334, 0.875, 0.9583333333333334, 0.9583333333333334]\n",
      "9 top features correlations above absolut values of 0.37914224376594957 give an mean accuracy = 0.9416666666666668 k-fold accuracies = [1.0, 0.9583333333333334, 0.875, 0.9583333333333334, 0.9166666666666666]\n",
      "8 top features correlations above absolut values of 0.4021775213783072 give an mean accuracy = 0.95 k-fold accuracies = [1.0, 0.9583333333333334, 0.875, 0.9583333333333334, 0.9583333333333334]\n",
      "7 top features correlations above absolut values of 0.40586096082835194 give an mean accuracy = 0.9583333333333334 k-fold accuracies = [1.0, 0.9583333333333334, 0.875, 1.0, 0.9583333333333334]\n",
      "6 top features correlations above absolut values of 0.49027409192176635 give an mean accuracy = 0.9583333333333334 k-fold accuracies = [1.0, 0.9583333333333334, 0.875, 1.0, 0.9583333333333334]\n",
      "5 top features correlations above absolut values of 0.490286791929897 give an mean accuracy = 0.9583333333333334 k-fold accuracies = [1.0, 0.9583333333333334, 0.875, 1.0, 0.9583333333333334]\n",
      "4 top features correlations above absolut values of 0.5083041546749706 give an mean accuracy = 0.9583333333333334 k-fold accuracies = [1.0, 0.9583333333333334, 0.875, 1.0, 0.9583333333333334]\n",
      "3 top features correlations above absolut values of 0.5256190618585365 give an mean accuracy = 0.9583333333333334 k-fold accuracies = [1.0, 0.9583333333333334, 0.875, 1.0, 0.9583333333333334]\n",
      "2 top features correlations above absolut values of 0.5317227182858683 give an mean accuracy = 0.9583333333333334 k-fold accuracies = [1.0, 0.9583333333333334, 0.875, 1.0, 0.9583333333333334]\n",
      "1 top features correlations above absolut values of 0.624200743278875 give an mean accuracy = 0.9583333333333334 k-fold accuracies = [0.9583333333333334, 0.9583333333333334, 0.9166666666666666, 1.0, 0.9583333333333334]\n"
     ]
    }
   ],
   "source": [
    "X_train_pearson=X_train\n",
    "features=features[:-1] #remove event itself\n",
    "nrOfFeatures=len(features)\n",
    "for feature in features:\n",
    "    if nrOfFeatures>1:\n",
    "        X_train_pearson=X_train_pearson.drop(feature,axis=1)\n",
    "        nrOfFeatures=nrOfFeatures-1\n",
    "        acc=CrossVal(X_train_pearson,Y_train)\n",
    "        print(str(nrOfFeatures) + \" top features \"+ \"correlations above absolut values of \" + str(abs(corr_columns[feature])) +\" give an mean accuracy = \" + str(np.mean(acc)) + \" k-fold accuracies = \"+ str(acc) ) \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03545d38",
   "metadata": {},
   "source": [
    "The code above showed that only the top feautre (crest_factor) was really needed to train the SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3959c64",
   "metadata": {},
   "source": [
    "Next, a wrapper method was implemented: forward feature selection. All features were tested individually, and only the best-performing one was retained. Then a brute-force approach was applied by combining the best feature with each of the remaining ones. The most effective combinations were preserved, and this process was repeated iteratively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0489864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores:\n",
      "[0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.9583333333333334, 0.95, 0.8916666666666666, 0.95, 0.9416666666666668, 0.9583333333333334, 0.95, 0.95, 0.95, 0.9416666666666668]\n",
      "removing feature crest_factor # worst score: 0.8916666666666666 features left: 15\n",
      "scores:\n",
      "[0.8916666666666666, 0.9083333333333332, 0.9, 0.925, 0.9083333333333332, 0.9, 0.8583333333333332, 0.9083333333333332, 0.9, 0.85, 0.8916666666666666, 0.9, 0.8916666666666666, 0.9, 0.8583333333333334]\n",
      "removing feature zero_crossings # worst score: 0.85 features left: 14\n",
      "scores:\n",
      "[0.8583333333333334, 0.85, 0.8333333333333333, 0.8666666666666666, 0.8333333333333333, 0.85, 0.7333333333333334, 0.85, 0.85, 0.8333333333333334, 0.85, 0.8583333333333334, 0.85, 0.8333333333333334]\n",
      "removing feature kurtosis # worst score: 0.7333333333333334 features left: 13\n",
      "scores:\n",
      "[0.7333333333333333, 0.7250000000000001, 0.7250000000000001, 0.725, 0.725, 0.7416666666666667, 0.7250000000000001, 0.7333333333333334, 0.7333333333333333, 0.7333333333333334, 0.7333333333333334, 0.7583333333333333, 0.7333333333333334]\n",
      "removing feature min # worst score: 0.725 features left: 12\n",
      "scores:\n",
      "[0.7166666666666667, 0.7333333333333333, 0.7166666666666667, 0.7, 0.7333333333333333, 0.7333333333333333, 0.7333333333333333, 0.7666666666666667, 0.7333333333333333, 0.7416666666666666, 0.7166666666666666, 0.7000000000000001]\n",
      "removing feature range # worst score: 0.7 features left: 11\n",
      "scores:\n",
      "[0.7, 0.7, 0.6666666666666666, 0.7083333333333334, 0.7, 0.7, 0.725, 0.7, 0.7, 0.6833333333333333, 0.6916666666666667]\n",
      "removing feature max # worst score: 0.6666666666666666 features left: 10\n",
      "scores:\n",
      "[0.6583333333333334, 0.6583333333333332, 0.675, 0.6583333333333332, 0.675, 0.7083333333333333, 0.675, 0.6666666666666666, 0.6666666666666666, 0.6416666666666667]\n",
      "removing feature spectral_flatness # worst score: 0.6416666666666667 features left: 9\n",
      "scores:\n",
      "[0.6249999999999999, 0.625, 0.6416666666666667, 0.625, 0.6416666666666667, 0.6916666666666667, 0.6416666666666667, 0.6333333333333333, 0.6833333333333333]\n",
      "removing feature mean # worst score: 0.6249999999999999 features left: 8\n",
      "scores:\n",
      "[0.6166666666666666, 0.65, 0.6166666666666666, 0.6333333333333332, 0.6833333333333333, 0.6333333333333332, 0.625, 0.6333333333333333]\n",
      "removing feature std # worst score: 0.6166666666666666 features left: 7\n",
      "scores:\n",
      "[0.6416666666666666, 0.6166666666666666, 0.6249999999999999, 0.7, 0.6166666666666666, 0.6249999999999999, 0.6333333333333334]\n",
      "removing feature rms # worst score: 0.6166666666666666 features left: 6\n",
      "scores:\n",
      "[0.6083333333333333, 0.575, 0.65, 0.575, 0.6166666666666666, 0.6]\n",
      "removing feature variance # worst score: 0.575 features left: 5\n",
      "scores:\n",
      "[0.6000000000000001, 0.6416666666666667, 0.625, 0.575, 0.6083333333333333]\n",
      "removing feature spectral_centroid # worst score: 0.575 features left: 4\n",
      "scores:\n",
      "[0.6, 0.65, 0.6166666666666666, 0.5999999999999999]\n",
      "removing feature spectral_bandwidth # worst score: 0.5999999999999999 features left: 3\n",
      "scores:\n",
      "[0.6416666666666666, 0.725, 0.5583333333333333]\n",
      "removing feature spectral_energy # worst score: 0.5583333333333333 features left: 2\n",
      "scores:\n",
      "[0.6083333333333334, 0.6666666666666667]\n",
      "removing feature skewness # worst score: 0.6083333333333334 features left: 1\n",
      "According to back feature selection the best feature was:\n",
      "['dominant_freq']\n"
     ]
    }
   ],
   "source": [
    "features= corr_columns.index.tolist()[:-1] \n",
    "NrOfFeatures=len(features)\n",
    "def BackwardFeatureSelection(X,Y,featuresWanted=1):\n",
    "    testFeaturesRemoved=[]\n",
    "    nrOfFeatures=len(X.columns)\n",
    "    while nrOfFeatures>featuresWanted:\n",
    "        scores=[]\n",
    "        testfeautures=[feat for feat in X.columns if feat not in testFeaturesRemoved]\n",
    "        for feature in testfeautures:\n",
    "            acc=CrossVal(X[[feat for feat in X.columns if (feat!=feature and feat not in testFeaturesRemoved) ]],Y_train)\n",
    "            scores.append(np.mean(acc))\n",
    "        lowestScoreIndex=scores.index(min(scores))\n",
    "        testFeaturesRemoved.append(testfeautures[lowestScoreIndex])\n",
    "        print(\"scores:\")\n",
    "        print(scores)\n",
    "        print(\"removing feature \"+ str(testfeautures[lowestScoreIndex]) + \" # worst score: \" + str( min(scores))  +\" features left: \" + str(len(testfeautures)-1))\n",
    "        nrOfFeatures=nrOfFeatures-1\n",
    "    print(\"According to back feature selection the best feature was:\")\n",
    "    print([feat for feat in X.columns if feat not in testFeaturesRemoved])    \n",
    "    #return X[[feat for feat in X.columns if feat not in testFeaturesRemoved]]\n",
    "BackwardFeatureSelection(X_train,Y_train,1)\n",
    "\n",
    "\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caeb4aa",
   "metadata": {},
   "source": [
    "One problem with the backwardselection method here is when removing a feature, several features gives similar scores, hence just the first one is removed in those cases. This is why crest_factor is removed at the first step, while from the pearson correlation we know this feature was very good to keep. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469a68fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores:\n",
      "[0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95]\n",
      "Adding feature mean # best score: 0.95 features selected: 1\n",
      "scores:\n",
      "[0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95]\n",
      "Adding feature std # best score: 0.95 features selected: 2\n",
      "scores:\n",
      "[0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95]\n",
      "Adding feature max # best score: 0.95 features selected: 3\n",
      "According to back feature selection the best features was:\n",
      "['mean', 'std', 'max']\n"
     ]
    }
   ],
   "source": [
    "features= corr_columns.index.tolist()[:-1] \n",
    "NrOfFeatures=len(features)\n",
    "def ForwardFeatureSelection(X,Y,featuresWanted=1):\n",
    "    testFeaturesSelected=[]\n",
    "    nrOfFeatures=0\n",
    "\n",
    "    if len(X.columns)<featuresWanted:\n",
    "        print(\"too many features, cant take more than \" + str(len(X.columns)) + \" features\")\n",
    "        featuresWanted=len(X.columns)\n",
    "\n",
    "    while nrOfFeatures<featuresWanted:\n",
    "        scores=[]\n",
    "        testfeautures=[feat for feat in X.columns if feat not in testFeaturesSelected]\n",
    "        for feature in testfeautures:\n",
    "            acc=CrossVal(X[[feat for feat in X.columns if (feat in testFeaturesSelected) or feat ]],Y_train)\n",
    "            scores.append(np.mean(acc))\n",
    "        highestScoreIndex=scores.index(max(scores))\n",
    "        print(\"scores:\")\n",
    "        print(scores)\n",
    "        testFeaturesSelected.append(testfeautures[highestScoreIndex])\n",
    "        print(\"Adding feature \"+ str(testfeautures[highestScoreIndex]) + \" # best score: \" + str( max(scores))  +\" features selected: \" + str(len(testFeaturesSelected)))\n",
    "        nrOfFeatures=nrOfFeatures+1\n",
    "    print(\"According to forward feature selection the best features was:\")\n",
    "    print([feat for feat in X.columns if feat in testFeaturesSelected])\n",
    " \n",
    "    #return X[[feat for feat in X.columns if feat not in testFeaturesRemoved]]\n",
    "ForwardFeatureSelection(X_train,Y_train,3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c89d99",
   "metadata": {},
   "source": [
    "This has the same problem as BackFeatureSelection, each feature does too little difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab642c8",
   "metadata": {},
   "source": [
    "Another feature selection algothim that we can use is relief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34eadecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['crest_factor', 'kurtosis', 'min', 'spectral_bandwidth', 'range'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from skrebate import ReliefF\n",
    "\n",
    "relief = ReliefF(n_features_to_select=5, n_neighbors=100)\n",
    "X_new = relief.fit_transform(X_train.values, Y_train.values)\n",
    "relief_selected_feature_indices = relief.top_features_[:relief.n_features_to_select]\n",
    "\n",
    "relief_selected_feature_names = X_train.columns[relief_selected_feature_indices]\n",
    "print(relief_selected_feature_names)  # Feature weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7699833",
   "metadata": {},
   "source": [
    "Using the features selected by ReliefF we get the following accuracy:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ec43f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy from using all the training data but only the top 3 features from ReliefF was: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "model=SVC()\n",
    "model.fit(X_train[relief_selected_feature_names],Y_train)\n",
    "y_pred= model.predict(X_test[relief_selected_feature_names])\n",
    "acc=accuracy_score(Y_test,y_pred)\n",
    "print(\"the accuracy from using all the training data but only the top 3 features from ReliefF was: \" + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9713687",
   "metadata": {},
   "source": [
    "### Observations and reflections\n",
    "Cross-validation can help detect overfitting; the SVM used did not show any pronounced signs of it.\n",
    "\n",
    "Backward and Forward selection algothims does not work too well when the difference of contribution from different features are not so pronounced. ReleifF can sometimes be considered to be very computationally intensive as it has to look for close neigbours of the data points themselves but this is no issue at all with the data amount for this assignment. The pearson correlation is well suited for a linear classificer, a single feature, crest_factor gave an accuracy of 96%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f3315a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eMaintenace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
